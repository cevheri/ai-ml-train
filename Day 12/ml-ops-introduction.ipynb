{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ccaafc5f4aac92",
   "metadata": {},
   "source": [
    "# Machine Learning Operations - MLOPS - Part1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c05da029ae8d60",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Building MachineLearning systems is hard. Some of the components you need:\n",
    "1. Data Sources\n",
    "2. Data Pipelines\n",
    "3. Feature Stores\n",
    "4. Model Training\n",
    "5. Model Evaluation\n",
    "6. Model Deployment\n",
    "7. Model Monitoring\n",
    "8. Predictions API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4c59792ef933",
   "metadata": {},
   "source": [
    "![](images/mlops-cycle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b772b91b7f0dd8",
   "metadata": {},
   "source": [
    "## MLOPS Introduction\n",
    "MLOps is a practice for collaboration and communication between data scientists and operations professionals to help manage the production machine learning lifecycle. This includes production deployment, model monitoring, and health, and managing the model's lifecycle. MLOps applies to the entire lifecycle - from integrating with model training, building CI/CD pipelines, and deploying models to production. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20047bcb97078f",
   "metadata": {},
   "source": [
    "## MLOPS Components\n",
    "### Data Sources\n",
    "Data sources are the sources of data that you use to train your models. These can be databases, data lakes, APIs, etc.\n",
    "\n",
    "### Data Pipelines\n",
    "Data pipelines are the processes that you use to clean, transform, and prepare your data for training. These can be ETL jobs, data processing jobs, etc.\n",
    "\n",
    "### Feature Stores\n",
    "Feature stores are the stores that you use to store the features that you use to train your models. These can be databases, data lakes, etc.\n",
    "\n",
    "### Model Training\n",
    "Model training is the process of training your models using the data that you have prepared. This can be done using machine learning libraries like scikit-learn, TensorFlow, PyTorch, etc.\n",
    "\n",
    "### Model Evaluation\n",
    "Model evaluation is the process of evaluating the performance of your models using metrics like accuracy, precision, recall, etc.\n",
    "\n",
    "### Model Deployment\n",
    "Model deployment is the process of deploying your models to production so that they can be used to make predictions. This can be done using tools like Docker, Kubernetes, etc.\n",
    "\n",
    "### Model Monitoring\n",
    "Model monitoring is the process of monitoring the performance of your models in production. This can be done using tools like Prometheus, Grafana, etc.\n",
    "\n",
    "### Predictions API\n",
    "Predictions API is the API that you use to make predictions using your models. This can be a REST API, gRPC API, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef906728c7d1e9",
   "metadata": {},
   "source": [
    "## MLOPS Tools\n",
    "There are many tools available for MLOps. Some of the popular ones are:\n",
    "1. Kubeflow\n",
    "2. MLFlow\n",
    "3. TFX\n",
    "4. Seldon\n",
    "5. Argo\n",
    "6. Airflow\n",
    "7. DVC\n",
    "8. Feast\n",
    "9. Cortex\n",
    "10. KFServing\n",
    "11. Sagemaker\n",
    "12. DataRobot\n",
    "13. H2O.ai\n",
    "14. DataRobot\n",
    "15. Pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe242ca436ae0f3",
   "metadata": {},
   "source": [
    "## MLOPS Best Practices\n",
    "1. Use version control for your code and data (e.g., Git\n",
    "2. Use containers for your models (e.g., Docker)\n",
    "3. Use automation for your pipelines (e.g., Jenkins, CircleCI)\n",
    "4. Use monitoring for your models (e.g., Prometheus, Grafana)\n",
    "5. Use logging for your models (e.g., ELK stack)\n",
    "6. Use testing for your models (e.g., unit tests, integration tests)\n",
    "7. Use security for your models (e.g., encryption, authentication)\n",
    "8. Use collaboration for your models (e.g., Jupyter notebooks, Slack)\n",
    "9. Use documentation for your models (e.g., README, Wiki)\n",
    "10. Use reproducibility for your models (e.g., DVC, MLFlow)\n",
    "11. Use scalability for your models (e.g., Kubernetes, Spark)\n",
    "12. Use optimization for your models (e.g., hyperparameter tuning, model selection)\n",
    "13. Use deployment for your models (e.g., Kubernetes, Seldon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65759903a4b34330",
   "metadata": {},
   "source": [
    "## MLOPS Challenges\n",
    "1. Data Quality\n",
    "2. Data Privacy\n",
    "3. Model Interpretability\n",
    "4. Model Fairness\n",
    "5. Model Robustness\n",
    "6. Model Scalability\n",
    "7. Model Security\n",
    "8. Model Governance\n",
    "9. Model Compliance\n",
    "10. Model Monitoring\n",
    "11. Model Versioning\n",
    "12. Model Deployment\n",
    "13. Model Maintenance\n",
    "14. Model Collaboration\n",
    "15. Model Documentation\n",
    "16. Model Reproducibility\n",
    "17. Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e7b0f18ff9d149",
   "metadata": {},
   "source": [
    "## Example code for MLOPS\n",
    "- Single line code - basic example . Next parts will have more detailed examples.\n",
    "- This code is for demonstration to show how to use MLOPS in practice. \n",
    "- It will load the hr dataset, train a linear regression model, and save the model to a file.\n",
    "- The code is simple and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1ca5f319cbe6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Libraries\n",
      "[53837.77000986]\n",
      "[67120.01434077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cevheri/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/cevheri/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing Libraries\")\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset \n",
    "# experience,test_score,interview_score,salary\n",
    "data = {\n",
    "    'experience': [0,  0,  5, 2,  7, 3, 10, 11],\n",
    "    'test_score': [8,  8,  6, 10, 9, 7, 5,  7],\n",
    "    'interview_score': [9, 6, 7, 10, 6, 10, 7, 8],\n",
    "    'salary': [50000, 45000, 60000, 65000, 70000, 62000, 72000, 80000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# model\n",
    "lr = LinearRegression()\n",
    "X = df[['experience', 'test_score', 'interview_score']]\n",
    "y = df['salary']\n",
    "model = lr.fit(X, y)\n",
    "pickle.dump(model, open('salary-calculator.pkl', 'wb'))\n",
    "\n",
    "# testing\n",
    "trained_model = pickle.load(open('salary-calculator.pkl', 'rb'))\n",
    "print(trained_model.predict([[2, 9, 6]]))\n",
    "print(trained_model.predict([[5, 7, 10]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d83ac80986562",
   "metadata": {},
   "source": [
    "## Explanation of the code\n",
    "1. Importing Libraries\n",
    "2. Creating a dataset (simple dataset with experience, test_score, interview_score, and salary)\n",
    "3. Creating a dataframe from the dataset\n",
    "4. Creating a Linear Regression model\n",
    "5. Training the model\n",
    "6. Saving the model to a file (salary-calculator.pkl) for later use, deployment(mobile app, web app, etc.)\n",
    "7. Loading the model from the file\n",
    "8. Making predictions using the model\n",
    "9. The model predicts the salary based on the experience, test_score, and interview_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b428a3b14cc808",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "* I hope you enjoyed this introduction to MLOps. In the next parts, we will dive deeper into each of the components of MLOps. Stay tuned!\n",
    "* I will create a series of posts on MLOps. Here are the title of the posts:\n",
    "\n",
    "\n",
    "1. Part1 - MLOPS - Introduction - Current Post\n",
    "2. Part2 - MLOPS - Data Pipelines\n",
    "3. Part3 - MLOPS - Model Training\n",
    "4. Part4 - MLOPS - Model Deployment\n",
    "5. Part5 - MLOPS - Model Monitoring\n",
    "6. Part6 - MLOPS - Predictions API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747568d9a54e5e64",
   "metadata": {},
   "source": [
    "\n",
    "## References\n",
    "- https://ml-ops.org/\n",
    "- https://en.wikipedia.org/wiki/MLOps\n",
    "- https://www.databricks.com/glossary/mlops\n",
    "- https://www.kdnuggets.com/10-github-repositories-to-master-mlops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
